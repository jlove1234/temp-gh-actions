        # Hourly scraping
name: nifty50scrape

# Controls when the action will run.
on:
  push:
    branches: main


jobs: 
  autoscrape:
    # The type of runner that the job will run on
    runs-on: macos-latest

    # Load repo and install R
    steps:
    - uses: actions/checkout@v2
    - uses: r-lib/actions/setup-r@v2

    # Set-up R
    - name: Install packages
      run: |
        R -e 'install.packages("tidyverse")'
        R -e 'install.packages("data.table")'
        R -e 'install.packages("rvest")'

    # Run R script
    - name: Scrape
      run: Rscript election_scrape.R

      # Upload the CSV file to AWS S3
    - name: Upload to AWS S3
      run: |
          aws s3 cp data/table_real.csv s3://
  
          # Upload the CSV file to AWS S3
    - name: Upload to AWS S3
      run: |
        aws s3 cp data/table_real.csv s3://jlovebucket-public/inflation-map/

      env:          
       AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
       AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
       AWS_REGION: ${{ secrets.AWS_REGION }}

 # Add new files in data folder, commit along with other modified files, push
    - name: Commit files
      run: |
        git config --local user.name actions-user
        git config --local user.email "actions@github.com"
        git add data/*
        git commit -am "GH ACTION Headlines $(date)"
        git push origin main
      env:
        REPO_KEY: ${{secrets.GITHUB_TOKEN}}
        username: github-actions

